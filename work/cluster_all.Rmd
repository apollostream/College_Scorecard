---
title: 'College Scorecard: Cluster Analysis'
author: "Michael L. Thompson"
date: "September 4, 2017"
output:
  pdf_document:
    toc: yes
    toc_depth: 4
  html_notebook:
    toc: yes
    toc_depth: 4
  html_document:
    toc: yes
    toc_depth: 4
linkcolor: red
always_allow_html: yes
urlcolor: blue
---

## Introduction

This is an exploratory analysis of the U.S. Dept. of Education College Scorecard database.  My intent is to 
investigate patterns amongst the colleges as visualized using 
[t-distributed Stochastic Neighbor Embedding](http://lvdmaaten.github.io/tsne/) (t-SNE)[^1] using the R package **Rtsne**[^2]. 
This method projects the high-dimensional data into two dimensions. 
From there, I can apply hierarchical clustering to identify clusters in the new 2-D space.

[^1]: L.J.P. van der Maaten. **Accelerating t-SNE using Tree-Based Algorithms.** *Journal of Machine Learning Research* 15(Oct):3221-3245, 2014.  [PDF](http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf) [[Supplemental material]](http://lvdmaaten.github.io/publications/misc/Supplement_JMLR_2014.pdf)

[^2]: Jesse H. Krijthe (2015). **Rtsne: T-Distributed Stochastic Neighbor Embedding using a Barnes-Hut Implementation**, URL: [https://github.com/jkrijthe/Rtsne](https://github.com/jkrijthe/Rtsne)

## Setup

First, load packages from the local library....

Note: The package **GraphAlignment** was downloaded and installed from BioConductor using the following R commands:

>    `source("http://bioconductor.org/biocLite.R")`   
     `biocLite("GraphAlignment")`

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if( file.exists("DataSpec.RData") ){
  load( "DataSpec.RData" )
  library('magrittr')  # for piping with infix %>%, %<>%, %T>% (for cool, sophistication effect)
  library('tidyverse')     # for reshaping data (e.g., 'gather')
  library('gridExtra') # for grid layout of ggplots
} else {
    source('~/GitHub/College_Scorecard/work/buildStaticDB.R', encoding = 'UTF-8', echo=TRUE)
}
library( Rtsne )
library( glmnet )
library( infotheo )
library( GraphAlignment )
library( cowplot )

```

## Prepare Data

We read in the College Scorecard dataset and convert columns into Bayes factors, which accentuate differences 
amongst the colleges. Colleges having a disproportionately high number of students with a certain attribute
-- say, an SAT in excess of 1400 -- will have highly positive Bayes factors for that attribute.


I strip out a lot of the variables that define the student body demographics.  The idea is that I'd
like to identify structure in the "outcome" variables -- things like academic disciplines,
completion rates, future earnings, 
credit default rates, etc. -- and then later check if this structure is correlated to demographics -- things
like geographic location, campus setting, student ethnicity, etc.

```{r make_df,warning=FALSE,message=FALSE}
glmdata_all <- DataSpec$studentBF %>%
  dplyr::select(
    c(-1, -(3:8)), -matches('_(WHITE|BLACK|ASIAN|OTHER|HISP|NRA|AIAN|UNKN)|2MOR|UNKN|NHPI|AIAN|BF_male|BF_is1st|IND_INC|DEP_INC|(LibraryScience)|(^discBreadth$)|female'),
    -matches('Challenge|_DEP_STAT_|notvet|le24y|OUTOFSTATE|prior|(^BF_[gl][et].+[0-9]+K$)|locale|FarWest|Plains|RockyM|GreatLakes|Southwest|Southeast|NewEngland|MidEast') 
  ) %>% 
  select_if( .predicate = function(x) any(x != x[[1]]) ) %>% 
  filter( complete.cases(.) )
tsne_mat_all <- glmdata_all %>% select(-College) %>% as.matrix() %>% scale()
```


## Perform t-Distributed Stochastic Neighbor Embedding (t-SNE)

Now, I'll map the data into a 2-D space using [t-SNE](http://lvdmaaten.github.io/tsne/).  Hopefully, it will be easy to see clusters of colleges.

It takes a bit of trial and error (short of doing a formal hyperparameter optimization) to arrive
at hyperparameters capable of generating discernible structure in a 2-D scatterplot.

```{r tsne }
set.seed( 173 )
tsne_all <- Rtsne( tsne_mat_all, perplexity = 10, initial_dims = 50, theta = 0.5, max_iter = 2000 )
```

### Rotate Coordinates

Now, I'll rotate the coordinates so that high-prestige colleges appear at high `Y2` coordinates. This will put most of the
Ivy League colleges in the top-center of the plot.

```{r rotate }
# Rotate coordinates so that high-prestige colleges appear at high Y2 coordinates, 
# i.e. in the top center of the plot.
i_harvard <- grep( 'Harvard', glmdata_all$College )
harvard_coord <- tsne_all$Y[i_harvard,]
harvard_angle <- atan(harvard_coord[2]/harvard_coord[1])
rotate_angle  <- pi/2 - harvard_angle
rotation_matrix <- matrix(
  c(cos(rotate_angle),sin(rotate_angle),-sin(rotate_angle),cos(rotate_angle)),
  2,2, byrow = TRUE
)
tsne_all$Y %<>% { (.) %*% rotation_matrix }
if( abs(tsne_all$Y[i_harvard,2]) < abs(tsne_all$Y[i_harvard,1]) ){
  tmp <- tsne_all$Y[,1]
  tsne_all$Y[,1] <- tsne_all$Y[,2]
  tsne_all$Y[,2] <- tmp
}
if( tsne_all$Y[i_harvard,2] < 0 ){
  tsne_all$Y[,2] <- -tsne_all$Y[,2]
}

```


I'll highlight colleges at the minimum and maximum of each of the coordinate axes and diagonals.  This is done by projecting
each college's coordinates onto vectors pointing into those 4 direction vectors -- up, right, top-right, top-left -- 
and finding the colleges that are at the maximum positive and negative points along those vectors.

The names of those colleges at the extremes are added along with "Harvard" as names to be highlighted in the 2-D scatterplot.

```{r tsne_plot,fig.height=10,fig.width=11}
# Project each college's coordinates along the 4 direction vectors.
prj <- tsne_all$Y %*% matrix(c(1,0,0,1,1,1,-1,1),nrow=2,ncol=4)

# Identify the colleges to be highlighted as Harvard and those at the min and max of the direction vectors.
highlights <- union(
  'Harvard',
  as.character(glmdata_all$College)[c(apply(prj,2,function(x) c(which.min(x),which.max(x))))]
) %>% 
  paste(collapse="|")

# Plot the 2D scatterplot with highlighted colleges labeled by the college name.
tsne_all$Y %>% 
  as_tibble() %>% 
  setNames(c('Y1','Y2')) %>%
  mutate( College = glmdata_all$College) %>% 
  { 
    ggplot(.,aes(x=Y1,y=Y2)) + 
      geom_point() +
      geom_text(
        data    = (.) %>% filter( grepl(highlights,College) ),
        mapping = aes( label = College ),
        color   = 'red',
        size    = 4
      )
  } %>% 
  print()

```


### Find Underlying Factors Driving 2-D Structure

Using R package [**glmnet**](https://www.jstatsoft.org/article/view/v033i01)[^3], 
I perform regularization (variable selection) in modeling of the 2-D t-SNE coordinates as responses vs. the
original college Bayes factor features from which the t-SNE coordinates were found.  This way we'll have a
linear model showing which features contributed to which coordinate.  As such,
we'll have the basis for plotting a biplot of colleges overlayed on feature dimensions in 2-D, 
analogous to a PCA biplot.

[^3]: Jerome Friedman, Trevor Hastie, Robert Tibshirani (2010). **Regularization Paths for Generalized Linear Models via Coordinate Descent.** *Journal of Statistical Software*, 33(1), 1-22. URL http://www.jstatsoft.org/v33/i01/.

```{r prep_glmnet}
mmat <- model.matrix( ~ .:. - 1, as.data.frame(tsne_mat_all))
# b <- eigen(cor(mmat))
# mmat <- mmat[,apply(b$vectors[,1:200],2,function(x) which.max(abs(x))) %>% unique() %>% sort()]
```

```{r glmnet}
set.seed( 2393 )
tsne_glmnet_all <- cv.glmnet(
  x      = mmat,
  y      = tsne_all$Y,
  family = 'mgaussian',
  lambda = exp(seq(log(0.05),log(10),length.out = 20))
)
plot( tsne_glmnet_all )
```

### Check the Predictions

It can be tricky to find a subset of features and their interactions that both describe the
t-SNE coordinates well *and* do not suffer from extreme collinearity, which can make the
validation error at low `lambda` explode when applying function `cv.glmnet()`.

Judging from the cross-validation curve above and the observed vs. predicted plots below, it looks
like we've got a decent model.


```{r pred_check, warning=FALSE, fig.width=10, fig.height=8}
# Get glmnet predictions of the t-SNE coordinates, combine them with the original t-SNE coordinates,
# and plot the originals vs. predictions.
lambda <- tsne_glmnet_all %$% { exp( mean(log(c(lambda.min,lambda.1se))) ) } # mid lambda
lambda <- 1.87654485

stack_coords <- function( coord_matrix ){
  coord_matrix %>%
    as_data_frame() %>% 
    setNames( c( "Y1", "Y2" ) ) %>% 
    mutate( rowid = 1:nrow(.) ) %>%
    gather( key = Coordinate, value = Value , -rowid )
}

# Plot t-SNE coords. vs. glmnet prediction of t-SNE coords.
tsne_glmnet_all %>% 
  predict( newx = mmat, s = lambda ) %>% 
  drop() %>% 
  stack_coords() %>%
  left_join( 
    y      = tsne_all$Y %>% stack_coords(), 
    by     = c('Coordinate','rowid'), 
    suffix = c( "_glmnet","_tSNE" ) 
  )  %>%
  {
    ggplot(., aes(x = Value_glmnet, y = Value_tSNE ) ) +
      geom_point( alpha = 0.3 ) +
      geom_abline( intercept = 0, slope = 1, color = 'red', linetype = 2, size = 1 ) +
      facet_wrap( ~ Coordinate ) +
      ggtitle( "t-SNE coordinates vs. glmnet predictions" ) +
      theme( text = element_text( face = 'bold' ) )
  } %>%
  print()

```

## Visualize the Colleges in 2-D

Analogous to PCA, which has component (i.e., factor) loading vectors defining the basis vectors (dimensions) of the space and
has a scores matrix defining the position of the items in the space, we'll use the 2-D t-SNE coordinates as our "factors" and as
such the **glmnet** coefficients are the factor "loadings" projecting the raw Bayes factor features of the colleges (our "items") into the 2-D space. Therefore the t-SNE coordinates of the colleges serve as the "scores" matrix.

### Get Factor "Loadings" from **glmnet** Coefficients

Now the **glmnet** model coefficients will serve as the basis vectors (dimensions) of the biplot, since
the model is simply a linear combo of the feature coefficients and each college's values for the respective features.

```{r derive_dimensions}

# Get the sparse matrix of coefficients and strip down to only the non-zero coefficients.
tsne_glmnet_coef_all <- tsne_glmnet_all %>% coef( s = lambda )

tsne_coef_df_all <- 
  tsne_glmnet_coef_all$y1 %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  rownames_to_column() %>% 
  setNames(c("Coefficient","Y1")) %>% 
  full_join(
    tsne_glmnet_coef_all$y2 %>% 
      as.matrix() %>% 
      as.data.frame() %>% 
      as_tibble() %>% 
      rownames_to_column() %>% 
      setNames(c("Coefficient","Y2")),
    by = "Coefficient"
  ) %>% 
  filter( abs(Y1) > 1.0E-9 | abs(Y2) > 1.0E-9 ) %>% slice(-1) %>%
  mutate(
    # Flip direction of interactions
    Y1 = ifelse( grepl(':',Coefficient), -Y1 , Y1 ),
    Y2 = ifelse( grepl(':',Coefficient), -Y2 , Y2 )
  )

tsne_coef_df_all %>% 
  mutate(mag = sqrt(Y1^2+Y2^2)) %>% 
  arrange(desc(mag)) %>% 
  mutate_at(funs(round(.,1)),.vars=vars(-Coefficient)) %>%
  print(n = 30)

# Designate coefficent vectors in the top 10% in magnitude as "key terms".
# And sort from largest magnitude to smallest.
key_terms <- tsne_coef_df_all %>% 
  mutate(mag= sqrt(Y1^2+Y2^2)) %>% 
  filter(abs(mag)>quantile(abs(mag),0.9)) %>% 
  arrange(desc(mag)) %$% Coefficient %>% setdiff("(Intercept)")
```

### Get "Scores" Matrix from t-SNE Coordinates

The college 2-D t-SNE coordinates are the "scores" matrix, which we collect into a `data_frame` with ancillary info for
labeling and coloring in our 2-D scatterplots.

```{r get_schools}
# For preliminary coloring in plot, divide colleges into categories that
# capture the 10, 25, 75 and 90 percentiles along the Y2 axis, which has bee
# rotated to point towards Ivy League colleges (specifically towards Harvard U.).
categories <- { 
  mmat[,key_terms] %*% 
    (tsne_coef_df_all %>% filter(Coefficient %in% key_terms) %$% Y2) 
} %>%
  sapply(
    function(x,q){ length(q) - sum(x>q) + 1 },
    q=quantile(.,c(0.1,0.25,0.75,0.9))
  ) %>%
  factor()

# Abbreviate names so they don't clutter the plots so much.
shorten_names <- function( df ){
  college_names <- df %$% 
    College %>%
    { gsub('^[0-9_]+','',. ) } %>%
    { gsub('The Univer.+ of Texas at ','U.T. ',.) } %>%
    { gsub('Advancement of Science','Adv.Sci',.) } %>%
    { gsub('Northwestern University','NU',.) } %>%
    { gsub('University of Notre Dame','Notre Dame U.',.) } %>%
    { gsub('Cornell College','Cornell C',.) } %>%
    { gsub('Cornell University','Cornell U',.) } %>%
    { gsub('California','Cal',. ) } %>%
    { gsub('Mass.+Inst.+Tech.+','MIT',. ) } %>%
    { gsub('(Mass|Penn|Wash)[^ ]+ *','\\1',.) } %>%
    { gsub('Polytechnic','Poly',. ) } %>%
    { gsub('Institute of Tech[^ ]+','IT',. ) } %>%
    { gsub('Tech.+Inst.+','Tech',. ) } %>%
    { gsub('State','St',. ) } %>%
    { gsub('University','U',. ) } %>%
    { gsub('(U of )|( U$)','',. ) } %>%
    { gsub('College','Col',. ) } %>%
    { gsub('New York','NY',.)} %>%
    { gsub('International','Intl',.) } %>%
    { gsub('North[^ ]+','N',.)} %>%
    { gsub('South[^ ]+','S',.)} %>%
    { gsub('West[^ ]+','W',.)} %>%
    { gsub('East[^ ]+','E',.)} %>%
    { gsub(' U-','-',.)} %>%
    { gsub('-Penn St ','',.)} %>%
    { gsub(' Col *$','',.)} %>%
    { gsub('-(Main)* Campus','',.)} %>%
    { gsub('^PennSt([^-]+)$','Penn St-\\1',.)} %>%
    { gsub(' and ','&',.)} %>%
    { gsub('Agricultural & Mechanical','A&M',.)}
  
  st_abb <- state.abb %>% setNames( state.name )
  for( st_nm in names(st_abb) ){
    college_names %<>% { gsub(st_nm,st_abb[st_nm],.) }
  }
  return( college_names )
}
college_names <- shorten_names( glmdata_all )
college_names_student <- shorten_names( DataSpec$student)

# Collect all colleges and their t-SNE coords, Bayes factor for high-income, and category designators in a data_frame()
tsne_df_all <- tsne_all$Y %>% 
  as_tibble() %>% 
  setNames(c("Y1","Y2")) %>% 
  mutate( 
    College = college_names, 
    category = categories,
    BF_Income_gt110K = glmdata_all %$% {10.0^BF_p_gt110K}
  ) %>% 
  dplyr::select( College, category, BF_Income_gt110K, everything() ) %>% 
  mutate_at(funs(scale(.)),.vars=vars(Y1,Y2))
```

### Show Biplot for Structure Interpretation

As with a PCA biplot, we can overlay the feature dimensions on the college scatterplot in the 2-D t-SNE coordinate space.  
This allows us to more easily interpret the structure we're seeing.  

However, some of the interaction terms, in particular,
are tricky to interpret because they have a positive value for a college if both of the features in the product
making up the interaction have the same sign.  So it could be that the college has a disproportionately higher
*or* lower number of students having the attributes of *both* of the corresponding features.

By plotting the College points sized by their Bayes factor on incomes greater than $110,000, we can see where the
colleges lie that have disproportionately high/low proportions of high-income students.

```{r biplot1,fig.height=10,fig.width=11}
# scale factor for coefficients:
f_mult <- 
  max(sqrt(tsne_df_all$Y1^2 + tsne_df_all$Y2^2))/
  max(sqrt(tsne_coef_df_all$Y1[-1]^2 + tsne_coef_df_all$Y2[-1]^2))

y2_min <- -3.5
tsne_coef_df_all %>% 
  mutate( 
    Y2 = pmax(y2_min,Y2*f_mult),
    Y1 = Y1*f_mult,
    mag = sqrt(Y1^2 + Y2^2),
    Coefficient = gsub('\\([^)]+\\)|(_*2005)|_','',gsub('BF_','',Coefficient))
  ) %>%
  {
    ggplot(., aes( x = Y1, y = Y2 ) ) +
      geom_point( color = 'red', alpha = 0.1 ) +
      # Labels for the coefficients
      geom_text( 
        aes( label = Coefficient), 
        color = 'red',
        alpha = 0.7,
        size = 3, 
        check_overlap = TRUE 
      ) + 
      # Rays on the coefficients
      geom_segment(
        inherit.aes = FALSE,
        data = (.) %>% filter(mag>1),
        aes( x=0, y=0, xend=Y1, yend=Y2 ),
        color = 'red',
        alpha = 0.3,
        arrow = arrow(length = unit(0.03, "npc"))
      ) + 
      # Labels for the Colleges
      geom_text(
        inherit.aes = FALSE,
        data = tsne_df_all,
        aes( x=Y1, y=Y2, label=College ),
        mapping=,
        color = 'black',
        size=3,
        check_overlap = TRUE
      )  +
      # Points for the colleges
      geom_point( data=tsne_df_all, aes(x=Y1,y=Y2, size = BF_Income_gt110K ), color='blue',alpha=0.1) +
      ggtitle( "t-SNE Biplot" , subtitle = "(blue = college, red = feature)") +
      theme( text = element_text( face = 'bold' ) ) #+
      #scale_y_continuous(limits = c(y2_min,4))
    #scale_y_continuous(limits = c(y2_min,4))
  } %>%
  print()
```


### Perform Hierarchical Clustering

Now, I perform cluster analysis.  Hierarchical clustering is a quick way to identify clusters in the
2-D t-SNE space.  We can then color the clusterings in a scatterplot to more easily visualize the structure.

```{r clustering}
tsne_mat_hc_all <- tsne_df_all %>% select(Y1,Y2) %>% as.matrix() %>% set_rownames(tsne_df_all$College)
hc_all <- hclust( d = dist( tsne_mat_hc_all ), method = 'single' )
n_cluster <- 55
cluster_id_all <- cutree( hc_all, k = n_cluster )

# plot( tsne_mat_hc, pch=20, cex=0.5 )
# for(j in seq_along(cl)){ 
#   points( tsne_mat_hc[ cl[[j]], ], pch=20, col=j, cex=1)
# }

# randomize so adjacent clusters are more likely to have very different colors.
set.seed(137)
cluster_id_all <- setNames( sample.int(n_cluster)[cluster_id_all], names(cluster_id_all) )
```

```{r cluster_display,fig.height=10,fig.width=11}
tsne_mat_hc_all %>%
  as_tibble() %>%
  mutate( College = names(cluster_id_all), cluster = factor( cluster_id_all ) ) %>%
  {
    ggplot(.,aes( x = Y1, y = Y2, color = cluster ) ) +
      geom_point( size = 1, alpha = 0.3 ) +
      geom_text( aes(label = College ), size = 3, check_overlap = TRUE ) +
      theme(
        text = element_text( face = 'bold' ),
        legend.position = 'none' 
      )
  } %>%
  print()
```

#### Characterize the Clusters

For each cluster, calculate its mutual information with each (discretized) Bayes factor.

```{r clstr_mi}
fctr_clstr <- factor( sprintf( "C%02d", cluster_id_all ) )
# df_cluster <- DataSpec$studentBF %>%  
#   dplyr::select( College,one_of( unlist(strsplit(key_terms,":"))) ) %>% 
#   mutate( cluster = fctr_clstr ) %>% 
#   gather( key= Feature, value = Value, -cluster, -College )

key_features <- unique(unlist(strsplit(tsne_coef_df_all$Coefficient,":")))

df_cluster <- mmat %>% 
  as_tibble() %>% 
  dplyr::select( one_of( key_features ) ) %>%
  bind_cols(DataSpec$studentBF %>% dplyr::select(unitID,College)) %>% 
  mutate(cluster = fctr_clstr) %>%
  gather( key= Feature, value = Value, one_of( key_features ) ) %>%
  mutate( Feature = gsub('BF_','',Feature ) )

df_median <- df_cluster %>% 
  group_by(Feature,cluster) %>% 
  summarize_at(funs(median),.vars=vars(Value)) %>% 
  ungroup()

#set.seed(131)
college_label <- DataSpec$studentBF %>% 
  mutate( 
    cluster = fctr_clstr, 
    shortname = college_names, 
    Y1 = tsne_df_all$Y1, 
    Y2 = tsne_df_all$Y2 
  ) %>% 
  group_by(cluster) %>% 
  summarize(
    i_max = which.max(BF_SAT_gt1400),
    name_max_SAT   = shortname[i_max],
    unitID_max_SAT = unitID[i_max],
    Y1_max = Y1[i_max],
    Y2_max = Y2[i_max]
  )

nm_max <- college_label %$% { setNames( name_max_SAT, as.character(cluster) ) }
Y1_max <- college_label %$% { setNames( Y1_max, as.character(cluster) ) }
Y2_max <- college_label %$% { setNames( Y2_max, as.character(cluster) ) }

df_mi <- df_cluster %>% 
  left_join( college_label, by = 'cluster' ) %>%
  group_by( Feature ) %>% 
  do(
    {
      feature <- (.)$Feature[[1]]
      sapply(
        levels(fctr_clstr),
        function(clstr, min_lvl, nm_max, Y1_max, Y2_max ) {
          c( 
            name_max_SAT = nm_max[[clstr]],
            Y1_max  = Y1_max[[clstr]],
            Y2_max  = Y2_max[[clstr]],
            Cluster = clstr,
            median  = df_median %>% filter(Feature == feature, cluster == clstr ) %$% Value,
            mi      = (.) %$% 
              mutinformation( 
                cluster == clstr, 
                if( length( unique(Value) ) <= min_lvl ) {
                  as.character(Value) 
                } else {
                  discretize( data.frame( Value = Value ) )
                }
              )
          )
        },
        min_lvl = 5,
        nm_max = nm_max, Y1_max = Y1_max, Y2_max = Y2_max
      ) %>% 
        t() %>%
        as_data_frame() %>%
        mutate( 
          Feature = feature, 
          median  = as.double(median), 
          mi      = as.double(mi), 
          Cluster = factor(Cluster) 
        ) %>% 
        dplyr::select( Feature, Cluster, median, mi, name_max_SAT )
    }
  ) %>% ungroup()

df_mi_rel <- df_mi %>% 
  group_by(Cluster) %>% 
  mutate(is_max = mi %>% {. == max(.)}) %>% 
  ungroup() %>% 
  mutate( mi_rel = round(sign(median)*mi/max(mi),2) )  %>% 
  arrange(Cluster, desc(mi) ) %>%
  dplyr::select( Cluster, Feature, mi_rel, everything() )

df_mi %<>% 
  left_join( df_mi_rel %>% dplyr::select( 1:3 ), by = c('Cluster','Feature') )%>% 
  mutate( Cluster_label = sprintf("%s (%s:{%4.1f,%4.1f})", Cluster, name_max_SAT,Y1_max,Y2_max ) )

```

Print a table of the features that most strongly characterize each cluster.

```{r print_mi}
df_mi_rel %>% 
  filter(mi>=0.02 | is_max ) %>% 
  mutate_at(funs(round(.,2)),.vars=vars(median,mi)) %>%  
  print(n=Inf)

```

Plot all features of each cluster.

```{r plot_mi,fig.width=8,fig.height=11}

i_clstr_min <- 0L
n_per_plot <- 14L
n_seq <- fctr_clstr %>% nlevels() %>% {seq(n_per_plot,.,length.out = ./n_per_plot) %>% ceiling()} %>% floor()
for( i_clstr_max in n_seq ){
  df_mi %>% filter(  as.integer(Cluster) > i_clstr_min, as.integer(Cluster) <= i_clstr_max ) %>%
  {
    ggplot(., aes( x = Feature, y = mi_rel, fill = Feature ) ) +
      geom_bar( stat = 'identity', position = 'dodge' ) +
      ylim( c(-1,1) ) +
      facet_wrap( ~ Cluster_label, nrow = 7, ncol = 2 ) +
      ggtitle( 
        label = "Characterization of Clusters by Feature", 
        subtitle = "sign(median(Feature|Cluster==k))*MI(Cluster==k,Feature)/max(MI(Cluster,Feature))") +
      theme( 
        text = element_text( face = 'bold' ),
        axis.text.x = element_text(angle=90,hjust=1,vjust=0.5, size = 6 ),
        legend.position = 'none'
      )
  } %>% 
    print()
  i_clstr_min <- i_clstr_max
}

```

### Show Biplot with Cluster Coloring

Finally, we can overlay the feature dimensions on the 2-D plot with cluster coloring.

```{r biplot_prep}
# Get cluster id for `n_cluster` number of clusters.
cluster_id_all <- cutree( hc_all, k = n_cluster )

# Determine bounds of coordinates for plot.
y2_min <- -4
y2_max <- 3.49
y1 <- range(tsne_mat_hc_all[,1])
y1[1] <- 0.5*floor(y1[1]/0.5)
y1[2] <- 0.5*ceiling(y1[2]/0.5)
y2 <- range(tsne_mat_hc_all[,2])
y2[1] <- 0.5*floor(y2[1]/0.5)
y2[2] <- 0.5*ceiling(y2[2]/0.5)

is_out_of_bounds <- function(x,bounds){ x<bounds[1] | x>bounds[2] }
# Assumes that value violating bounds is of same sign as bound violated AND that bounds are of opposite signs.
bound_factor <- function(x,bounds){
  f1 <- ifelse(x<bounds[1],x/bounds[1],0)
  f2 <- ifelse(x>bounds[2],x/bounds[2],0)
  mapply(function(b1,b2) if(b1>b2) c(1,b1) else c(2,b2),f1,f2)
}
tsne_modified <- tsne_coef_df_all %>% 
  mutate( 
    Coefficient = gsub('\\([^)]+\\)|(_*2005)|_','',gsub('BF_','',Coefficient)),
    Y1  = f_mult*Y1,
    Y2  = f_mult*Y2 ,
    mag = sqrt(Y1^2 + Y2^2)
  ) 

# check bounds to find if any violated
bchk1 <- bound_factor(tsne_modified$Y1,y1)
bchk2 <- bound_factor(tsne_modified$Y2,y2)
# bound on Y1 violated
w1 <- which(bchk1[2,] != 0)
# bound on Y2 violated
w2 <- which(bchk2[2,] != 0)
# Keep only coord Y1 or Y2 violated the most by each violating pt.
for( i in intersect(w1,w2)) { if(bchk1[2,i]>bchk2[2,i]) w2<-setdiff(w2,i) else w1<- setdiff(w1,i) }
# bound on Y1 violated: fix it
for( i in w1 ){
  tsne_modified$Y2[i] <- tsne_modified$Y2[i]*y1[bchk1[1,i]]/tsne_modified$Y1[i]
  tsne_modified$Y1[i] <- y1[bchk1[1,i]]
}
# bound on Y2 violated: fix it
for( i in w2 ){
  tsne_modified$Y1[i] <- tsne_modified$Y1[i]*y2[bchk2[1,i]]/tsne_modified$Y2[i]
  tsne_modified$Y2[i] <- y2[bchk2[1,i]]
}
```

```{r biplot2,fig.height=10,fig.width=11}
# Plot cluster-colored biplot.
tsne_modified %>%
  {
    ggplot(., aes( x = Y1, y = Y2 ) ) +
      geom_point( color = 'red', alpha = 0.1 ) + 
      geom_segment(
        inherit.aes = FALSE,
        data = (.) %>% filter(mag>1),
        aes( x=0, y=0, xend=Y1, yend=Y2 ),
        color = 'red',
        alpha = 0.3,
        arrow = arrow(length = unit(0.03, "npc"))
      ) + 
      geom_text(
        inherit.aes = FALSE,
        data = tsne_mat_hc_all %>%
          as_tibble() %>%
          mutate( 
            College = names(cluster_id_all), 
            cluster = factor( (cluster_id_all %% 7) + 1 )
          ),
        aes( x=Y1, y=Y2, label=College, color = cluster ),
        mapping=,
        show.legend = FALSE,
        size=2,
        check_overlap = TRUE
      ) +
      geom_text( 
        aes( label = Coefficient ), 
        color = 'black',
        size = 3, 
        check_overlap = TRUE
      )  +
      geom_point( 
        data = tsne_mat_hc_all %>%
          as_tibble() %>%
          mutate( 
            College = names(cluster_id_all), 
            cluster = factor( (cluster_id_all %% 7) + 1 ),
            cluster_shape = factor( (cluster_id_all %% 6) + 1 )
          ), 
        aes(x=Y1,y=Y2, color = cluster, shape = cluster_shape ), 
        show.legend = FALSE,
        alpha=0.3
      ) +
      ggtitle(
        label    = "American College Landscape",
        subtitle = "t-SNE Biplot with Bayes factors as features" 
        ) +
      theme( text = element_text( face = 'bold' ) ) #+
      #scale_y_continuous(limits = c(y2_min,5))
  } %>%
  print()
```

## Graph Alignment: Linear Assignment Problem

The t-SNE coordinates can be mapped to a regular 2-D grid by solving the Linear Assignment Problem [^4],[^5],[^6].

[^4]: Blog post by by Vadim Markovtsev, 14 March 2017: [Jonker-Volgenant Algorithm + t-SNE = Super Powers](https://blog.sourced.tech/post/lapjv/?utm_source=Mailing+list&utm_campaign=8ed002c926-Kaggle_Newsletter_04-11-2017&utm_medium=email&utm_term=0_f42f9df1e1-8ed002c926-399303201)   
[^5]: R. Jonker and A. Volgenant, **"A Shortest Augmenting Path Algorithm for Dense and Sparse Linear Assignment Problems,"** *Computing*, vol. **38**, pp. 325-340, 1987.  
[^6]: See: [Linear Assignment Problem solver using Jonker-Volgenant algorithm](https://github.com/src-d/lapjv).  

### Demonstrate LAP Graph Alignment

We first apply LAP Graph Alignment to a simple problem.

```{r lap_demo_0,fig.width=9,fig.height=3}
set.seed( 13115 )
N_obs <- 50^2
N_clstr <- 6L
mu  <- matrix( rt(N_clstr*2, df = 3),ncol=2 )
p   <- rgamma(N_clstr,3,2) %>% {(.)/sum(.)}
n   <- (p*N_obs) %>% ceiling() %>% {c(N_obs-sum(.[-1]),(.)[-1])}

m   <- n %>% 
  seq_along() %>% 
  lapply(function(ix) (matrix( rnorm(n[ix]*2,sd=0.5), n[ix], 2 )+matrix(mu[ix,],n[ix],2,byrow=2))) %>%
  {do.call(rbind,.)} %>%
  {((.)-min(.))/diff(range(.))}

par_old <- par( no.readonly = TRUE )
par(mfrow=c(1,3))
plot(m,col=rep(seq_along(n),times=n),main = 'Raw Points w/Original Colors' )

m_tsne <- m %>% 
  Rtsne() %$%
  Y %>%
  {((.)-min(.))/diff(range(.))}
plot(m_tsne,col=rep(seq_along(n),times=n), main = 't-SNE w/Original Colors' )

hc  <- m_tsne %>% dist() %>% hclust() %>% cutree(k=N_clstr)
grid <- expand.grid(1:sqrt(N_obs),1:sqrt(N_obs)) %>% as.matrix() %>% {((.)-min(.))/diff(range(.))}
plot(m_tsne,col=hc, main = 't-SNE w/Hierachical Clustering Colors')

par( par_old )
```

```{r lap_demo_1,fig.width=10,fig.height=10}
cost_matrix <- matrix(NA,nrow(m_tsne),nrow(grid))
for( i in seq_len(nrow(m_tsne))){
  for(j in seq_len(nrow(grid))){
    cost_matrix[i,j] <- sqrt( sum((m_tsne[i,] - grid[j,])^2) )
  }
}
cost_matrix = cost_matrix * (100000 / max(cost_matrix) )

px <- LinearAssignment( cost_matrix )

m_df <- m[px,] %>% 
  set_colnames(c("X1","X2") ) %>% 
  cbind( m_tsne[px,] %>% set_colnames(c("X1_tsne","X2_tsne") )) %>%
  cbind(grid) %>% 
  as_tibble() %>% 
  mutate( cluster = factor( hc[px] ), row_id = as.character(1:nrow(.)) )

plts <- list(
  original = m_df %>%
  {
    ggplot(.,aes(x=X1,y=X2,color=cluster)) +
      geom_point(size=2) +
      lims( x=c(0,1.04), y=c(0,1.04) ) +
      #geom_text( aes(label = row_id),nudge_y=0.02,size=2) +
      theme( legend.position = 'none' )
  },
  tsne = m_df %>%
  {
    ggplot(.,aes(x=X1_tsne,y=X2_tsne,color=cluster)) +
      geom_point(size=2) +
      lims( x=c(0,1.04), y=c(0,1.04) ) +
      #geom_text( aes(label = row_id),nudge_y=0.02,size=2) +
      theme( legend.position = 'none' )
  },
  assigned = m_df %>%
  { 
    ggplot(.,aes(x=X1_tsne,y=X2_tsne,color=cluster) ) + 
      geom_point(size=2 ) + 
      geom_segment(
        aes(xend=Var1,yend=Var2),
        arrow = arrow( length = unit(0.2,"cm") ), 
        #color = 'gray', 
        alpha = 0.4 
      ) + 
      geom_point( aes(x=Var1,y=Var2), size=1, alpha = 0.3) +
      #geom_text( aes(x=Var1,y=Var2,label = row_id),nudge_y=0.02,size=2) +
      theme( legend.position = 'none' )
  },
  final = m_df %>%
  { 
    ggplot(.,aes(x=Var1,y=Var2,color=cluster) ) + 
      geom_point(size=2 ) +
      lims( x=c(0,1.04), y=c(0,1.04) ) +
      #geom_text( aes(label = row_id),nudge_y=0.02,size=2) +
      theme( legend.position = 'none' )
  }
)
plot_grid( plts$original, plts$tsne, plts$assigned, plts$final, ncol = 2, nrow = 2, labels = c("1","2","3","4") ) %>%
  print()
```

### Perform Graph Alignment on t-SNE Coordinates

Now, we apply it to the college dataset t-SNE coordinates.

```{r graph_align,fig.width=10,fig.height=8}
N_obs <- nrow( tsne_mat_hc_all )
grid <- expand.grid(1:floor(sqrt(N_obs)),1:ceiling(sqrt(N_obs))) %>% as.matrix() %>% {((.)-min(.))/diff(range(.))}
grid <- grid[1:N_obs,]

tsne_scaled <- tsne_mat_hc_all %>% {((.)-min(.))/diff(range(.))}
cost_matrix <- matrix(NA,N_obs,nrow(grid))
for( i in seq_len(nrow(cost_matrix))){
  for(j in seq_len(ncol(cost_matrix))){
    cost_matrix[i,j] <- sqrt( sum((tsne_scaled[i,] - grid[j,])^2) )
  }
}
cost_matrix = cost_matrix * (100000 / max(cost_matrix) )
rm( tsne_scaled )

px <- LinearAssignment( cost_matrix )

tsne_mat_hc_all %>%
  as_tibble() %>%
  mutate( 
    College = names( cluster_id_all), 
    cluster = factor( (cluster_id_all %% 7) + 1 )
  ) %>%
  slice( px ) %>%
  cbind( grid * diff(range(tsne_mat_hc_all)) + min(tsne_mat_hc_all) ) %>%
  {
    ggplot(.,aes( x = Var1, y = Var2 ) ) + 
      geom_text(
        inherit.aes = FALSE,
        mapping     = aes( x = Var1, y = Var2 , label = College, color = cluster ),
        show.legend = FALSE,
        size        = 2,
        angle       = 45,
        fontface    = 'bold',
        check_overlap = TRUE
      )
  } %>%
  plot()
```

## Conclusions

We do find some structure in the plot. And, the rotation of the axis to put Harvard University at the
top-center helps us to interpret the axes and give meaning to that structure. 

### Notable Colleges

Clusters are colored with repeating colors and marked with repeating symbols, reflecting a limit
of **ggplot2**. But each cluster should have an unique color-symbol combination.

Here are the t-SNE 2-D coordinates for some notable universities:

```{r notables}
select_colleges <- c(
  '^OH St', '^MI-Ann Arbor', '^Purdue$', '^NU$','Harvard',
  'Yale', 'Princeton','^Penn$','^Cornell$','^Brown$',
  '^Howard$','Tuskegee','Hampton','Morehouse','Grambling',
  'Bethune-Cookman','Stanford','Johns Hopkins','Duke','Vanderbilt',
  'Rice','Wash.+St Louis','Notre Dame U\\.','^Pomona$','Harvey Mudd',
  'Swarthmore','MIT','Cal *IT','WI-Madison','IN-Bloomington',
  'Dartmouth',"Otis Col of Art&Design","San Francisco Art Institute",
  "Watkins Col of Art Design & Film","Rose-Hulman IT",
  "Worcester Poly Institute","GA IT Campus","Davidson"
)

names( select_colleges ) <- 
  c(
    "Ohio State","Michigan","Purdue","Northwestern",
    "Harvard","Yale","Princeton","Penn","Cornell","Brown",
    "Howard","Tuskegee","Hampton Inst","Morehouse","Grambling","Bethune-Cookman",
    "Stanford","Johns Hopkins","Duke","Vanderbilt","Rice","Wash.U.-St.L.",
    "Notre Dame","Pomona","Harvey Mudd","Swarthmore",
    "MIT","CalTech","Wisconsin","Indiana","Dartmouth",
    "Otis Col of Art&Design","San Francisco Art Institute","Watkins Col of Art Design & Film",
    "Rose-Hulman IT","Worcester Poly Institute","Georgia Tech","Davidson"
  )

rowid_select <- sapply( select_colleges, function(nm_regex) grep(nm_regex,tsne_df_all$College) )

sat_ugds_select <- DataSpec$student %>% 
  slice( sapply( select_colleges, function(nm_regex) grep(nm_regex,college_names_student) ) ) %>%
  dplyr::select(1:2,UGDS,SAT_AVG,pctDisc1,pctDisc2,C150_4_POOLED_SUPP,CDR3,median_hh_inc_2005,pell_ever_2005,PAR_ED_PCT_1STGEN) %>%
  mutate(
    UGDS = prettyNum( UGDS, big.mark = "," ),
    SAT_AVG = round(SAT_AVG),
    median_hh_inc_2005 = prettyNum(100*round(median_hh_inc_2005/100),big.mark=","),
    pctDisc_top2 = round(pctDisc1+pctDisc2),
    cluster = cluster_id_all[rowid_select]
  ) %>%
  dplyr::select(1:2,pctDisc_top2,everything(),-pctDisc1,-pctDisc2) %>%
  left_join( 
    DataSpec$studentBF %>% 
      dplyr::select(unitID,BF_discBreadth,BF_SAT_gt1400,BF_not1stgen,BF_fsend_5_2005,BF_CDR3),
    by = "unitID"
  )

tsne_select <- tsne_df_all %>% 
  slice( rowid_select ) %$%
  set_rownames(as.matrix(select(.,Y1,Y2)),College) %>% 
  round(1)

```



| Group |     College     |  Y1 | Y2 |  SAT avg. | Cluster | Comments |
|------:|----------------:|----:|:---|----------:|--------:|:---------|
| **Ivy League** | Harvard         | `r tsne_select[ 5,1]` | `r tsne_select[ 5,2]` | `r sat_ugds_select$SAT_AVG[ 5]` | `r sat_ugds_select$cluster[ 5]` |
|                | Yale            | `r tsne_select[ 6,1]` | `r tsne_select[ 6,2]` | `r sat_ugds_select$SAT_AVG[ 6]` | `r sat_ugds_select$cluster[ 6]` |
|                | Penn            | `r tsne_select[ 8,1]` | `r tsne_select[ 8,2]` | `r sat_ugds_select$SAT_AVG[ 8]` | `r sat_ugds_select$cluster[ 8]` |
|                | Princeton       | `r tsne_select[ 7,1]` | `r tsne_select[ 7,2]` | `r sat_ugds_select$SAT_AVG[ 7]` | `r sat_ugds_select$cluster[ 7]` |
|                | Dartmouth       | `r tsne_select[31,1]` | `r tsne_select[31,2]` | `r sat_ugds_select$SAT_AVG[31]` | `r sat_ugds_select$cluster[31]` |
|                | Brown           | `r tsne_select[10,1]` | `r tsne_select[10,2]` | `r sat_ugds_select$SAT_AVG[10]` | `r sat_ugds_select$cluster[10]` |
|                | Cornell         | `r tsne_select[ 9,1]` | `r tsne_select[ 9,2]` | `r sat_ugds_select$SAT_AVG[ 9]` | `r sat_ugds_select$cluster[ 9]` |
|   **Big 10**   | Ohio State      | `r tsne_select[ 1,1]` | `r tsne_select[ 1,2]` | `r sat_ugds_select$SAT_AVG[ 1]` | `r sat_ugds_select$cluster[ 1]` |
|                | Wisconsin       | `r tsne_select[29,1]` | `r tsne_select[29,2]` | `r sat_ugds_select$SAT_AVG[29]` | `r sat_ugds_select$cluster[29]` |
|                | Purdue          | `r tsne_select[ 3,1]` | `r tsne_select[ 3,2]` | `r sat_ugds_select$SAT_AVG[ 3]` | `r sat_ugds_select$cluster[ 3]` |
|                | Indiana         | `r tsne_select[30,1]` | `r tsne_select[30,2]` | `r sat_ugds_select$SAT_AVG[30]` | `r sat_ugds_select$cluster[30]` |
|                | Michigan        | `r tsne_select[ 2,1]` | `r tsne_select[ 2,2]` | `r sat_ugds_select$SAT_AVG[ 2]` | `r sat_ugds_select$cluster[ 2]` | is more like Ivies than Big10
|                | Northwestern    | `r tsne_select[ 4,1]` | `r tsne_select[ 4,2]` | `r sat_ugds_select$SAT_AVG[ 4]` | `r sat_ugds_select$cluster[ 4]` | is more like Ivies than Big10
|   **HBCUs**    | Howard          | `r tsne_select[11,1]` | `r tsne_select[11,2]` | `r sat_ugds_select$SAT_AVG[11]` | `r sat_ugds_select$cluster[11]` |
|                | Tuskegee        | `r tsne_select[12,1]` | `r tsne_select[12,2]` | `r sat_ugds_select$SAT_AVG[12]` | `r sat_ugds_select$cluster[12]` |
|                | Hampton Inst    | `r tsne_select[13,1]` | `r tsne_select[13,2]` | `r sat_ugds_select$SAT_AVG[13]` | `r sat_ugds_select$cluster[13]` |
|                | Morehouse       | `r tsne_select[14,1]` | `r tsne_select[14,2]` | `r sat_ugds_select$SAT_AVG[14]` | `r sat_ugds_select$cluster[14]` |
|                | Grambling       | `r tsne_select[15,1]` | `r tsne_select[15,2]` | `r sat_ugds_select$SAT_AVG[15]` | `r sat_ugds_select$cluster[15]` |
|                | Bethune-Cookman | `r tsne_select[16,1]` | `r tsne_select[16,2]` | `r sat_ugds_select$SAT_AVG[16]` | `r sat_ugds_select$cluster[16]` |
| **Arts Specialty** | SF Art Inst     | `r tsne_select[33,1]` | `r tsne_select[33,2]` | `r sat_ugds_select$SAT_AVG[33]` | `r sat_ugds_select$cluster[33]` |
|                    | Otis C Art&Des  | `r tsne_select[32,1]` | `r tsne_select[32,2]` | `r sat_ugds_select$SAT_AVG[32]` | `r sat_ugds_select$cluster[32]` |
|                    | Watkins Art,Des,Film  | `r tsne_select[34,1]` | `r tsne_select[34,2]` | `r sat_ugds_select$SAT_AVG[34]` | `r sat_ugds_select$cluster[34]` |
| **Tech Specialty** | Rose-Hullman    | `r tsne_select[35,1]` | `r tsne_select[35,2]` | `r sat_ugds_select$SAT_AVG[35]` | `r sat_ugds_select$cluster[35]` |
|                    | Georgia Tech    | `r tsne_select[37,1]` | `r tsne_select[37,2]` | `r sat_ugds_select$SAT_AVG[37]` | `r sat_ugds_select$cluster[37]` |
|                    | WPI             | `r tsne_select[36,1]` | `r tsne_select[36,2]` | `r sat_ugds_select$SAT_AVG[36]` | `r sat_ugds_select$cluster[36]` |
|   **Others**       | Stanford        | `r tsne_select[17,1]` | `r tsne_select[17,2]` | `r sat_ugds_select$SAT_AVG[17]` | `r sat_ugds_select$cluster[17]` |
|                    | MIT             | `r tsne_select[27,1]` | `r tsne_select[27,2]` | `r sat_ugds_select$SAT_AVG[27]` | `r sat_ugds_select$cluster[27]` |
|                    | CalTech         | `r tsne_select[28,1]` | `r tsne_select[28,2]` | `r sat_ugds_select$SAT_AVG[28]` | `r sat_ugds_select$cluster[28]` |
|                    | Johns Hopkins   | `r tsne_select[18,1]` | `r tsne_select[18,2]` | `r sat_ugds_select$SAT_AVG[18]` | `r sat_ugds_select$cluster[18]` |
|                    | Duke            | `r tsne_select[19,1]` | `r tsne_select[19,2]` | `r sat_ugds_select$SAT_AVG[19]` | `r sat_ugds_select$cluster[19]` |
|                    | Vanderbilt      | `r tsne_select[20,1]` | `r tsne_select[20,2]` | `r sat_ugds_select$SAT_AVG[20]` | `r sat_ugds_select$cluster[20]` |
|                    | Rice            | `r tsne_select[21,1]` | `r tsne_select[21,2]` | `r sat_ugds_select$SAT_AVG[21]` | `r sat_ugds_select$cluster[21]` |
|                    | Wash.U.-St.L.   | `r tsne_select[22,1]` | `r tsne_select[22,2]` | `r sat_ugds_select$SAT_AVG[22]` | `r sat_ugds_select$cluster[22]` |
|                    | Notre Dame      | `r tsne_select[23,1]` | `r tsne_select[23,2]` | `r sat_ugds_select$SAT_AVG[23]` | `r sat_ugds_select$cluster[23]` |
|                    | Pomona          | `r tsne_select[24,1]` | `r tsne_select[24,2]` | `r sat_ugds_select$SAT_AVG[24]` | `r sat_ugds_select$cluster[24]` |
|                    | Harvey Mudd     | `r tsne_select[25,1]` | `r tsne_select[25,2]` | `r sat_ugds_select$SAT_AVG[25]` | `r sat_ugds_select$cluster[25]` |
|                    | Swarthmore      | `r tsne_select[26,1]` | `r tsne_select[26,2]` | `r sat_ugds_select$SAT_AVG[26]` | `r sat_ugds_select$cluster[26]` |
|                    | Davidson        | `r tsne_select[38,1]` | `r tsne_select[38,2]` | `r sat_ugds_select$SAT_AVG[38]` | `r sat_ugds_select$cluster[38]` |



### Interpretation of Quadrants

The combination of cluster locations and Bayes factors feature rays helps us assign meaning to
each quadrant of the biplot.

#### Elite private & top-academic public, wealthy & smart

The vertical `Y2` axis is now almost perfectly aligned with the ray `pgt110K`, which is the ($\log_{10}$) Bayes factor capturing the prevalance of students from
families with annual incomes greater than $110,000. All the Ivy League, "Ivy wannabes", and top-academic public universities (e.g., Cal-Berkeley, U. Michigan-Ann Arbor) are
aligned along the positive vertical axis. That axis is almost perfectly countered by the downward-pointed ray `SATle800`, which is the Bayes factor capturing the prevalance of students with combined Verbal & Math SAT scores less than or equal to 800, i.e., the lowest tail of SAT scores.

### Breadth versus specialization

The horizontal `Y1` axis isn't so readily interpretable. However, we see the ray `discBreadth`, whcih is the feature capturing the entropy (variety) in academic disciplines in which
degrees are offered from the college, is pointing into the upper-left corner of the plot. So colleges aligned along this ray in the upper-right quadrant are the big public state universities that offer a broad range of degrees.  On the other hand, the narrowly, highly specialized colleges appear in the lower-right quadrant of the plot.

### Pell grants & high 3-yr credit default rates

The colleges in the lower-left quadrant are the colleges most strongly aligned with rays `pellever`, which captures prevalence of students having ever received a federal Pell grant, and `CDR3est`, which captures prevalence of students defaulting on student loans within 3 years of leaving
the college.

### More privates, but less elite

The upper-right quadrant is aligned with `SAT1400` (highest SAT students), `fsend5` (applied to many colleges), and `pgt48Kle75K` (mid-income families).


## Summary

This was an exploratory analysis investigating structure in the U.S. Dept. of Education
College Scorecard dataset.

